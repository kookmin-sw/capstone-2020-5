{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './benignData/'\n",
    "\n",
    "numFeatures  = 256\n",
    "minWordCount = 50\n",
    "windowSize   = 10\n",
    "numWorkers   = 7\n",
    "\n",
    "epochs = 10\n",
    "lr     = 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Assembly Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for fileName in os.listdir(path):\n",
    "#     filePath = path + fileName\n",
    "#     if os.path.isfile(filePath):\n",
    "#         d = pickle.load(open(filePath, 'rb'))\n",
    "#         for i in d:\n",
    "#             for j in i:\n",
    "#                 data.append(j)\n",
    "#                 \n",
    "# print('The number of data is ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim \n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawResult(model, fileName=None):\n",
    "    vocab = list(model.wv.vocab)\n",
    "    X     = model.wv[vocab]\n",
    "    tsne  = TSNE(n_components=2)\n",
    "    tsneX = tsne.fit_transform(X)\n",
    "    df    = pd.DataFrame(tsneX, index=vocab, columns=['x', 'y'])\n",
    "    \n",
    "    fig = plt.figure(figsize=(60, 60))\n",
    "    ax  = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "\n",
    "    for word, pos in df.iterrows():\n",
    "        ax.annotate(word, pos, fontsize=30)\n",
    "    plt.title(fileName)\n",
    "    plt.show()\n",
    "    \n",
    "    if fileName is not None:\n",
    "        fig.savefig(fileName + '.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecSentense(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fileName in os.listdir(self.dirname):\n",
    "            filePath = path + fileName\n",
    "            if os.path.isfile(filePath):\n",
    "                d = pickle.load(open(filePath, 'rb'))\n",
    "                for i in d:\n",
    "                    for j in i:\n",
    "                        yield j\n",
    "                        \n",
    "class EpochLogger(gensim.models.callbacks.CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.beginTime = 0\n",
    "    \n",
    "    def on_epoch_begin(self, model):\n",
    "        print('Epoch {} '.format(self.epoch), end='')\n",
    "        self.epoch += 1\n",
    "        self.beginTime = time.time()\n",
    "        \n",
    "    def on_epoch_end(self, model):\n",
    "        print('- {} sec'.format(int(time.time() - self.beginTime)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram (SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for numFeatures in [8, 16, 32, 64, 128, 256]:\n",
    "    print('----------------------------------------')\n",
    "    print('----------------- [{}] -----------------'.format(numFeatures))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    epochLogger = EpochLogger()\n",
    "    fileName = './result/SG_{}feature_{}window_{}minword_{}epochs'.format(numFeatures, windowSize, minWordCount, epochs)\n",
    "    SG = gensim.models.Word2Vec(Word2VecSentense(path), size=numFeatures, window=windowSize, min_count=minWordCount, workers=numWorkers, iter=epochs, sg=1, callbacks=[epochLogger])\n",
    "    SG.save(fileName)\n",
    "    drawResult(SG, fileName)\n",
    "\n",
    "    print('\\n---------- add ----------')\n",
    "    print(SG.wv.most_similar('add'))\n",
    "    print('\\n---------- mov ----------')\n",
    "    print(SG.wv.most_similar('mov'))\n",
    "    print('\\n---------- jmp ----------')\n",
    "    print(SG.wv.most_similar('jmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag Of Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for numFeatures in [8, 16, 32, 64, 128, 256]:\n",
    "    print('----------------------------------------')\n",
    "    print('----------------- [{}] -----------------'.format(numFeatures))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    epochLogger = EpochLogger()\n",
    "    fileName = './result/CBOW_{}feature_{}window_{}minword_{}epochs'.format(numFeatures, windowSize, minWordCount, epochs)\n",
    "    CBOW = gensim.models.Word2Vec(Word2VecSentense(path), size=numFeatures, window=windowSize, min_count=minWordCount, workers=numWorkers, iter=epochs, sg=0, callbacks=[epochLogger])\n",
    "    CBOW.save(fileName)\n",
    "    drawResult(CBOW, fileName)\n",
    "\n",
    "    print('\\n---------- add ----------')\n",
    "    print(CBOW.wv.most_similar('add'))\n",
    "    print('\\n---------- mov ----------')\n",
    "    print(CBOW.wv.most_similar('mov'))\n",
    "    print('\\n---------- jmp ----------')\n",
    "    print(CBOW.wv.most_similar('jmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2VecSentense(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fileName in os.listdir(self.dirname):\n",
    "            filePath = path + fileName\n",
    "            if os.path.isfile(filePath):\n",
    "                d = pickle.load(open(filePath, 'rb'))\n",
    "                for i in d:\n",
    "                    for j in i:\n",
    "                        yield gensim.models.doc2vec.TaggedDocument(j, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed-Memory (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numFeatures in [8, 16, 32, 64, 128, 256]:\n",
    "    print('----------------------------------------')\n",
    "    print('----------------- [{}] -----------------'.format(numFeatures))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    epochLogger = EpochLogger()\n",
    "    fileName = './result/DM_{}feature_{}window_{}minword_{}epochs'.format(numFeatures, windowSize, minWordCount, epochs)\n",
    "    DM = gensim.models.doc2vec.Doc2Vec(Doc2VecSentense(path), vector_size=numFeatures, window=windowSize, min_count=minWordCount, workers=numWorkers, epochs=epochs, dm=1, callbacks=[epochLogger])\n",
    "    DM.save(fileName)\n",
    "    drawResult(DM, fileName)\n",
    "\n",
    "    print('\\n---------- add ----------')\n",
    "    print(DM.wv.most_similar('add'))\n",
    "    print('\\n---------- mov ----------')\n",
    "    print(DM.wv.most_similar('mov'))\n",
    "    print('\\n---------- jmp ----------')\n",
    "    print(DM.wv.most_similar('jmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Bag Of Words (DBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for numFeatures in [8, 16, 32, 64, 128, 256]:\n",
    "    print('----------------------------------------')\n",
    "    print('----------------- [{}] -----------------'.format(numFeatures))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    epochLogger = EpochLogger()\n",
    "    fileName = './result/DBOW_{}feature_{}window_{}minword_{}epochs'.format(numFeatures, windowSize, minWordCount, epochs)\n",
    "    DBOW = gensim.models.doc2vec.Doc2Vec(Doc2VecSentense(path), vector_size=numFeatures, window=windowSize, min_count=minWordCount, workers=numWorkers, epochs=epochs, dm=0, callbacks=[epochLogger])\n",
    "    DBOW.save(fileName)\n",
    "    drawResult(DBOW, fileName)\n",
    "\n",
    "    print('\\n---------- add ----------')\n",
    "    print(DBOW.wv.most_similar('add'))\n",
    "    print('\\n---------- mov ----------')\n",
    "    print(DBOW.wv.most_similar('mov'))\n",
    "    print('\\n---------- jmp ----------')\n",
    "    print(DBOW.wv.most_similar('jmp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for numFeatures in [8, 16, 32, 64, 128, 256]:\n",
    "    print('----------------------------------------')\n",
    "    print('----------------- [{}] -----------------'.format(numFeatures))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    epochLogger = EpochLogger()\n",
    "    fileName = './result/FT_{}feature_{}window_{}minword_{}epochs'.format(numFeatures, windowSize, minWordCount, epochs)\n",
    "    FT = gensim.models.FastText(Word2VecSentense(path), size=numFeatures, window=windowSize, min_count=minWordCount, workers=numWorkers, iter=epochs, sg=1, callbacks=[epochLogger])\n",
    "    FT.save(fileName)\n",
    "    drawResult(FT, fileName)\n",
    "\n",
    "    print('\\n---------- add ----------')\n",
    "    print(FT.wv.most_similar('add'))\n",
    "    print('\\n---------- mov ----------')\n",
    "    print(FT.wv.most_similar('mov'))\n",
    "    print('\\n---------- jmp ----------')\n",
    "    print(FT.wv.most_similar('jmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for numFeatures in [8, 16, 32, 64, 128, 256]:\n",
    "    print('----------------------------------------')\n",
    "    print('----------------- [{}] -----------------'.format(numFeatures))\n",
    "    print('----------------------------------------')\n",
    "\n",
    "    epochLogger = EpochLogger()\n",
    "    fileName = './result/FT_CBOW_{}feature_{}window_{}minword_{}epochs'.format(numFeatures, windowSize, minWordCount, epochs)\n",
    "    FT = gensim.models.FastText(Word2VecSentense(path), size=numFeatures, window=windowSize, min_count=minWordCount, workers=numWorkers, iter=epochs, sg=0, callbacks=[epochLogger])\n",
    "    FT.save(fileName)\n",
    "    drawResult(FT, fileName)\n",
    "\n",
    "    print('\\n---------- add ----------')\n",
    "    print(FT.wv.most_similar('add'))\n",
    "    print('\\n---------- mov ----------')\n",
    "    print(FT.wv.most_similar('mov'))\n",
    "    print('\\n---------- jmp ----------')\n",
    "    print(FT.wv.most_similar('jmp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
